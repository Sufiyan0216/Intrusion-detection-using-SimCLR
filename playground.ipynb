{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import models\n",
    "import dataset\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Extractor(\n",
       "  (resnet): Net1D(\n",
       "    (first_conv): MyConv1dPadSame(\n",
       "      (conv): Conv1d(1, 20, kernel_size=(16,), stride=(2,))\n",
       "    )\n",
       "    (first_bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (first_activation): Swish()\n",
       "    (stage_list): ModuleList(\n",
       "      (0): BasicStage(\n",
       "        (block_list): ModuleList(\n",
       "          (0): BasicBlock(\n",
       "            (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation1): Swish()\n",
       "            (do1): Dropout(p=0.5, inplace=False)\n",
       "            (conv1): MyConv1dPadSame(\n",
       "              (conv): Conv1d(20, 64, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation2): Swish()\n",
       "            (do2): Dropout(p=0.5, inplace=False)\n",
       "            (conv2): MyConv1dPadSame(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(2,), groups=4)\n",
       "            )\n",
       "            (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation3): Swish()\n",
       "            (do3): Dropout(p=0.5, inplace=False)\n",
       "            (conv3): MyConv1dPadSame(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (se_fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (se_fc2): Linear(in_features=32, out_features=64, bias=True)\n",
       "            (se_activation): Swish()\n",
       "            (max_pool): MyMaxPool1dPadSame(\n",
       "              (max_pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "            )\n",
       "          )\n",
       "          (1-2): 2 x BasicBlock(\n",
       "            (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation1): Swish()\n",
       "            (do1): Dropout(p=0.5, inplace=False)\n",
       "            (conv1): MyConv1dPadSame(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation2): Swish()\n",
       "            (do2): Dropout(p=0.5, inplace=False)\n",
       "            (conv2): MyConv1dPadSame(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), groups=4)\n",
       "            )\n",
       "            (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation3): Swish()\n",
       "            (do3): Dropout(p=0.5, inplace=False)\n",
       "            (conv3): MyConv1dPadSame(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (se_fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (se_fc2): Linear(in_features=32, out_features=64, bias=True)\n",
       "            (se_activation): Swish()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): BasicStage(\n",
       "        (block_list): ModuleList(\n",
       "          (0): BasicBlock(\n",
       "            (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation1): Swish()\n",
       "            (do1): Dropout(p=0.5, inplace=False)\n",
       "            (conv1): MyConv1dPadSame(\n",
       "              (conv): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation2): Swish()\n",
       "            (do2): Dropout(p=0.5, inplace=False)\n",
       "            (conv2): MyConv1dPadSame(\n",
       "              (conv): Conv1d(256, 256, kernel_size=(16,), stride=(2,), groups=16)\n",
       "            )\n",
       "            (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation3): Swish()\n",
       "            (do3): Dropout(p=0.5, inplace=False)\n",
       "            (conv3): MyConv1dPadSame(\n",
       "              (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (se_fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (se_fc2): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (se_activation): Swish()\n",
       "            (max_pool): MyMaxPool1dPadSame(\n",
       "              (max_pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "            )\n",
       "          )\n",
       "          (1-3): 3 x BasicBlock(\n",
       "            (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation1): Swish()\n",
       "            (do1): Dropout(p=0.5, inplace=False)\n",
       "            (conv1): MyConv1dPadSame(\n",
       "              (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation2): Swish()\n",
       "            (do2): Dropout(p=0.5, inplace=False)\n",
       "            (conv2): MyConv1dPadSame(\n",
       "              (conv): Conv1d(256, 256, kernel_size=(16,), stride=(1,), groups=16)\n",
       "            )\n",
       "            (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation3): Swish()\n",
       "            (do3): Dropout(p=0.5, inplace=False)\n",
       "            (conv3): MyConv1dPadSame(\n",
       "              (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (se_fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (se_fc2): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (se_activation): Swish()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): BasicStage(\n",
       "        (block_list): ModuleList(\n",
       "          (0): BasicBlock(\n",
       "            (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation1): Swish()\n",
       "            (do1): Dropout(p=0.5, inplace=False)\n",
       "            (conv1): MyConv1dPadSame(\n",
       "              (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation2): Swish()\n",
       "            (do2): Dropout(p=0.5, inplace=False)\n",
       "            (conv2): MyConv1dPadSame(\n",
       "              (conv): Conv1d(256, 256, kernel_size=(16,), stride=(2,), groups=16)\n",
       "            )\n",
       "            (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation3): Swish()\n",
       "            (do3): Dropout(p=0.5, inplace=False)\n",
       "            (conv3): MyConv1dPadSame(\n",
       "              (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (se_fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (se_fc2): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (se_activation): Swish()\n",
       "            (max_pool): MyMaxPool1dPadSame(\n",
       "              (max_pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "            )\n",
       "          )\n",
       "          (1-5): 5 x BasicBlock(\n",
       "            (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation1): Swish()\n",
       "            (do1): Dropout(p=0.5, inplace=False)\n",
       "            (conv1): MyConv1dPadSame(\n",
       "              (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation2): Swish()\n",
       "            (do2): Dropout(p=0.5, inplace=False)\n",
       "            (conv2): MyConv1dPadSame(\n",
       "              (conv): Conv1d(256, 256, kernel_size=(16,), stride=(1,), groups=16)\n",
       "            )\n",
       "            (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation3): Swish()\n",
       "            (do3): Dropout(p=0.5, inplace=False)\n",
       "            (conv3): MyConv1dPadSame(\n",
       "              (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (se_fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (se_fc2): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (se_activation): Swish()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): BasicStage(\n",
       "        (block_list): ModuleList(\n",
       "          (0): BasicBlock(\n",
       "            (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation1): Swish()\n",
       "            (do1): Dropout(p=0.5, inplace=False)\n",
       "            (conv1): MyConv1dPadSame(\n",
       "              (conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation2): Swish()\n",
       "            (do2): Dropout(p=0.5, inplace=False)\n",
       "            (conv2): MyConv1dPadSame(\n",
       "              (conv): Conv1d(512, 512, kernel_size=(16,), stride=(2,), groups=32)\n",
       "            )\n",
       "            (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation3): Swish()\n",
       "            (do3): Dropout(p=0.5, inplace=False)\n",
       "            (conv3): MyConv1dPadSame(\n",
       "              (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (se_fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "            (se_fc2): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (se_activation): Swish()\n",
       "            (max_pool): MyMaxPool1dPadSame(\n",
       "              (max_pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "            )\n",
       "          )\n",
       "          (1-2): 2 x BasicBlock(\n",
       "            (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation1): Swish()\n",
       "            (do1): Dropout(p=0.5, inplace=False)\n",
       "            (conv1): MyConv1dPadSame(\n",
       "              (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation2): Swish()\n",
       "            (do2): Dropout(p=0.5, inplace=False)\n",
       "            (conv2): MyConv1dPadSame(\n",
       "              (conv): Conv1d(512, 512, kernel_size=(16,), stride=(1,), groups=32)\n",
       "            )\n",
       "            (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation3): Swish()\n",
       "            (do3): Dropout(p=0.5, inplace=False)\n",
       "            (conv3): MyConv1dPadSame(\n",
       "              (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (se_fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "            (se_fc2): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (se_activation): Swish()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dense): Linear(in_features=512, out_features=34, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with open('./dist/resnet/extractor1d-170.pkl', 'rb') as f:\n",
    "    extractor = pickle.load(f)\n",
    "\n",
    "extractor.to(device)\n",
    "extractor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_resnet = extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtractorMLP(\n",
       "  (conv1d): MyConv1dPadSame(\n",
       "    (conv): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (linear_in): Linear(in_features=20, out_features=65, bias=True)\n",
       "  (backbone): Sequential(\n",
       "    (linear-0): Linear(in_features=65, out_features=65, bias=True)\n",
       "    (act-0): ReLU()\n",
       "  )\n",
       "  (linear_out): Linear(in_features=65, out_features=39, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./dist/mlp/extractor1d-final.pkl', 'rb') as f:\n",
    "    extractor = pickle.load(f)\n",
    "\n",
    "extractor.to(device)\n",
    "extractor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_mlp = extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5338790"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_resnet_params = count_parameters(extractor_resnet)\n",
    "cnt_resnet_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8231"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_mlp_params = count_parameters(extractor_mlp)\n",
    "cnt_mlp_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_consumption(cnt, gadge='GB'):\n",
    "    # KB, MB, GB\n",
    "    if gadge == 'KB':\n",
    "        mul = 10\n",
    "    elif gadge == 'MB':\n",
    "        mul = 20\n",
    "    else:\n",
    "        gadge = 30\n",
    "\n",
    "    mem_comsumption = {\n",
    "        'f32': f\"{cnt*4/2**mul:5}{gadge}\",\n",
    "        'f16': f\"{cnt*2/2**mul:5}{gadge}\",\n",
    "        'i8': f\"{cnt*1/2**mul:5}{gadge}\",\n",
    "    }\n",
    "\n",
    "    return mem_comsumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f32': '32.15234375KB', 'f16': '16.076171875KB', 'i8': '8.0380859375KB'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_consumption(cnt_mlp_params, gadge='KB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f32': '20.365867614746094MB',\n",
       " 'f16': '10.182933807373047MB',\n",
       " 'i8': '5.091466903686523MB'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_consumption(cnt_resnet_params, gadge='MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import  train_test_split\n",
    "\n",
    "data_files = [name for name in os.listdir('./data')]\n",
    "dfs = []\n",
    "\n",
    "for i in range(len(data_files)):\n",
    "    fname = './data/' + data_files[i]\n",
    "    df = pd.read_csv(fname)\n",
    "    # df.columns = [x.strip().lstrip() for x in df.columns]\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "# Remove spaces in the front and the end of the column names for better human reading\n",
    "df.columns = [x.lstrip().strip().replace('ï¿½', '-') for x in df.columns]\n",
    "\n",
    "# replace inf values to nan\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df_train, df_val = train_test_split(df, stratify=df['Label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_val.drop(['Label'], axis=1)\n",
    "y = df_val['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dist/labelencoder-resnet.pkl', 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "with open('./dist/preprocessor-resnet.pkl', 'rb') as f:\n",
    "    preprocessor = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.transform(X)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565576"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.expand_dims(X, axis=2).transpose((0, 2, 1))\n",
    "\n",
    "dataset = dataset.NumpyDataset(X, y)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed 14.002958536148071s\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "embeddings = []\n",
    "labels = []\n",
    "batch_size = 1024\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for X, y in dataloader:\n",
    "    X = X.to(device)\n",
    "    X_embedding = extractor_resnet(X)\n",
    "    embeddings.append(X_embedding.cpu().detach().numpy())\n",
    "\n",
    "    labels.append(y)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"elapsed {end - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed 2.366269588470459s\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "embeddings = []\n",
    "labels = []\n",
    "batch_size = 1024\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for X, y in dataloader:\n",
    "    X = X.to(device)\n",
    "    X_embedding = extractor_mlp(X)\n",
    "    embeddings.append(X_embedding.cpu().detach().numpy())\n",
    "\n",
    "    labels.append(y)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"elapsed {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chan/Documents/CSI5388/project/resnet1d/net1d.py:56: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n",
      "/home/chan/miniconda3/envs/csi5388/lib/python3.10/site-packages/torch/onnx/_internal/jit_utils.py:306: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343967769/work/torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/home/chan/miniconda3/envs/csi5388/lib/python3.10/site-packages/torch/onnx/utils.py:689: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343967769/work/torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/home/chan/miniconda3/envs/csi5388/lib/python3.10/site-packages/torch/onnx/utils.py:1186: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343967769/work/torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "input_names = [\"PCA\"]\n",
    "output_names = [\"embedding\"]\n",
    "\n",
    "X_export = X[:128, :, :]\n",
    "\n",
    "torch.onnx.export(extractor_mlp, X_export, \"extractor_mlp.onnx\", input_names=input_names, output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chan/Documents/CSI5388/project/resnet1d/net1d.py:56: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n",
      "/home/chan/miniconda3/envs/csi5388/lib/python3.10/site-packages/torch/onnx/_internal/jit_utils.py:306: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343967769/work/torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/home/chan/miniconda3/envs/csi5388/lib/python3.10/site-packages/torch/onnx/utils.py:689: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343967769/work/torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/home/chan/miniconda3/envs/csi5388/lib/python3.10/site-packages/torch/onnx/utils.py:1186: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343967769/work/torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(extractor_resnet, X_export, \"extractor_resnet.onnx\", input_names=input_names, output_names=output_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csi5388",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
