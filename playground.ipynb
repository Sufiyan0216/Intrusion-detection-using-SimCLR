{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "from sklearn.utils import resample\n",
    "from collections import Counter\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import helper\n",
    "import dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from resnet1d.net1d import Net1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2830743, 79)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = [name for name in os.listdir('./data')]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for i in range(len(data_files)):\n",
    "    fname = './data/' + data_files[i]\n",
    "    df = pd.read_csv(fname)\n",
    "    # df.columns = [x.strip().lstrip() for x in df.columns]\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2830743, 79)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove spaces in the front and the end of the column names for better human reading\n",
    "df.columns = [x.lstrip().strip().replace('ï¿½', '-') for x in df.columns]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2827876, 79)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace inf values to nan\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove this when experimenting on the whole dataset\n",
    "df = resample(df, replace=False, n_samples=20000, stratify=df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pca__n_components = 20\n",
    "\n",
    "preprocessor = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy='most_frequent')),\n",
    "    (\"normalize\", MinMaxScaler()),\n",
    "    (\"PCA\", PCA(n_components=pca__n_components))\n",
    "])\n",
    "\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Label'], axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_val = preprocessor.transform(X_val)\n",
    "\n",
    "# doing this since we need all labels in case there's any labels not found in test set\n",
    "label_encoder.fit(y)\n",
    "\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 3, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smote, _ = helper.smote_sampling(X_train, y_train)\n",
    "X_gaussion = helper.add_gaussion(X_smote)\n",
    "X_flip = helper.invert_array(X_train)\n",
    "\n",
    "X_new = np.dstack([X_smote, X_gaussion, X_flip])\n",
    "X_new = X_new.transpose((0, 2, 1))\n",
    "\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 1, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch, channel, feature\n",
    "X_train = np.expand_dims(X_train, axis=2).transpose((0, 2, 1))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_dataset = dataset.NumpyDataset(X_train, y_train)\n",
    "pos_dataset = dataset.NumpyDataset(X_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from pytorch_metric_learning.losses import SelfSupervisedLoss, NTXentLoss\n",
    "from models import Extractor, Projector\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "extractor_1d = Extractor(n_features=pca__n_components, n_channels=1).to(device)\n",
    "extractor_3d = Extractor(n_features=pca__n_components, n_channels=3).to(device)\n",
    "\n",
    "projector = Projector().to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-4\n",
    "batch_size = 128\n",
    "epochs = 200\n",
    "\n",
    "org_dataloader = DataLoader(org_dataset, batch_size=batch_size,)\n",
    "pos_dataloader = DataLoader(pos_dataset, batch_size=batch_size)\n",
    "\n",
    "optimizer_1d = torch.optim.Adam(extractor_1d.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "optimizer_3d = torch.optim.Adam(extractor_3d.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "optimizer_projector = torch.optim.Adam(projector.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "loss_fn = NTXentLoss()\n",
    "loss_fn = SelfSupervisedLoss(loss_fn, symmetric=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/200]: 526.4330174922943\n",
      "[1/200]: 360.79523730278015\n",
      "[2/200]: 326.10967469215393\n",
      "[3/200]: 308.4385435581207\n",
      "[4/200]: 292.6241066455841\n",
      "[5/200]: 274.16411900520325\n",
      "[6/200]: 257.2951933145523\n",
      "[7/200]: 244.62671315670013\n",
      "[8/200]: 229.48354721069336\n",
      "[9/200]: 215.93647027015686\n",
      "[10/200]: 206.07626259326935\n",
      "[11/200]: 197.43839848041534\n",
      "[12/200]: 187.03276336193085\n",
      "[13/200]: 186.04748022556305\n",
      "[14/200]: 174.28682219982147\n",
      "[15/200]: 175.02989542484283\n",
      "[16/200]: 171.25295209884644\n",
      "[17/200]: 167.69488072395325\n",
      "[18/200]: 161.35639584064484\n",
      "[19/200]: 160.70035004615784\n",
      "[20/200]: 161.0859353542328\n",
      "[21/200]: 154.04450166225433\n",
      "[22/200]: 148.15520495176315\n",
      "[23/200]: 148.78121149539948\n",
      "[24/200]: 149.76501202583313\n",
      "[25/200]: 148.18415957689285\n",
      "[26/200]: 141.98402070999146\n",
      "[27/200]: 139.79235023260117\n",
      "[28/200]: 139.27884125709534\n",
      "[29/200]: 136.90944987535477\n",
      "[30/200]: 135.4210729598999\n",
      "[31/200]: 134.62163192033768\n",
      "[32/200]: 130.68104380369186\n",
      "[33/200]: 128.15140742063522\n",
      "[34/200]: 133.04172468185425\n",
      "[35/200]: 132.51252299547195\n",
      "[36/200]: 134.88134747743607\n",
      "[37/200]: 128.6970847249031\n",
      "[38/200]: 122.44484806060791\n",
      "[39/200]: 128.17668306827545\n",
      "[40/200]: 131.04802280664444\n",
      "[41/200]: 131.56188893318176\n",
      "[42/200]: 124.24373412132263\n",
      "[43/200]: 122.65144896507263\n",
      "[44/200]: 118.44651108980179\n",
      "[45/200]: 118.90501832962036\n",
      "[46/200]: 117.34133875370026\n",
      "[47/200]: 114.8848329782486\n",
      "[48/200]: 119.6844145655632\n",
      "[49/200]: 119.43356758356094\n",
      "[50/200]: 115.4417576789856\n",
      "[51/200]: 113.62907183170319\n",
      "[52/200]: 115.69944816827774\n",
      "[53/200]: 112.70266729593277\n",
      "[54/200]: 113.23905450105667\n",
      "[55/200]: 112.81510782241821\n",
      "[56/200]: 112.84561800956726\n",
      "[57/200]: 110.36487758159637\n",
      "[58/200]: 111.36224645376205\n",
      "[59/200]: 112.73529088497162\n",
      "[60/200]: 110.44377106428146\n",
      "[61/200]: 107.79404532909393\n",
      "[62/200]: 106.57023042440414\n",
      "[63/200]: 106.02971482276917\n",
      "[64/200]: 102.83562648296356\n",
      "[65/200]: 106.97563308477402\n",
      "[66/200]: 106.8560329079628\n",
      "[67/200]: 101.87890619039536\n",
      "[68/200]: 104.77350664138794\n",
      "[69/200]: 104.000368475914\n",
      "[70/200]: 99.59338164329529\n",
      "[71/200]: 101.24600201845169\n",
      "[72/200]: 100.42168527841568\n",
      "[73/200]: 101.49856543540955\n",
      "[74/200]: 98.00445139408112\n",
      "[75/200]: 95.73026156425476\n",
      "[76/200]: 97.60412710905075\n",
      "[77/200]: 96.72497928142548\n",
      "[78/200]: 95.90583890676498\n",
      "[79/200]: 94.83666414022446\n",
      "[80/200]: 96.29547137022018\n",
      "[81/200]: 98.02486777305603\n",
      "[82/200]: 93.00279754400253\n",
      "[83/200]: 95.25778180360794\n",
      "[84/200]: 95.04324752092361\n",
      "[85/200]: 92.43929678201675\n",
      "[86/200]: 91.08437287807465\n",
      "[87/200]: 92.19692355394363\n",
      "[88/200]: 92.91868090629578\n",
      "[89/200]: 90.14424043893814\n",
      "[90/200]: 93.37916988134384\n",
      "[91/200]: 92.23620223999023\n",
      "[92/200]: 89.85056030750275\n",
      "[93/200]: 88.33942925930023\n",
      "[94/200]: 91.59559565782547\n",
      "[95/200]: 88.75302052497864\n",
      "[96/200]: 86.79579943418503\n",
      "[97/200]: 86.32822382450104\n",
      "[98/200]: 85.47007352113724\n",
      "[99/200]: 84.26223593950272\n",
      "[100/200]: 86.02590042352676\n",
      "[101/200]: 84.49730014801025\n",
      "[102/200]: 86.24525320529938\n",
      "[103/200]: 84.06997421383858\n",
      "[104/200]: 83.8115718960762\n",
      "[105/200]: 84.01804327964783\n",
      "[106/200]: 87.44523671269417\n",
      "[107/200]: 84.388532102108\n",
      "[108/200]: 83.67539012432098\n",
      "[109/200]: 81.41007614135742\n",
      "[110/200]: 79.89158943295479\n",
      "[111/200]: 85.3557881116867\n",
      "[112/200]: 81.35933411121368\n",
      "[113/200]: 79.4500982761383\n",
      "[114/200]: 80.09047129750252\n",
      "[115/200]: 82.00276428461075\n",
      "[116/200]: 79.6968086361885\n",
      "[117/200]: 79.6949118077755\n",
      "[118/200]: 79.67398324608803\n",
      "[119/200]: 77.08230155706406\n",
      "[120/200]: 78.31042411923409\n",
      "[121/200]: 80.61214426159859\n",
      "[122/200]: 77.30784279108047\n",
      "[123/200]: 80.05645096302032\n",
      "[124/200]: 78.34705466032028\n",
      "[125/200]: 78.60446107387543\n",
      "[126/200]: 78.28504750132561\n",
      "[127/200]: 79.88928371667862\n",
      "[128/200]: 76.15857988595963\n",
      "[129/200]: 75.86925455927849\n",
      "[130/200]: 75.27007529139519\n",
      "[131/200]: 76.86921295523643\n",
      "[132/200]: 75.57285112142563\n",
      "[133/200]: 75.81481847167015\n",
      "[134/200]: 76.27125930786133\n",
      "[135/200]: 77.39968982338905\n",
      "[136/200]: 75.78221669793129\n",
      "[137/200]: 76.98773440718651\n",
      "[138/200]: 75.92469009757042\n",
      "[139/200]: 76.6011765897274\n",
      "[140/200]: 74.69860884547234\n",
      "[141/200]: 74.85012033581734\n",
      "[142/200]: 73.52758219838142\n",
      "[143/200]: 75.44388407468796\n",
      "[144/200]: 74.53434467315674\n",
      "[145/200]: 74.51435896754265\n",
      "[146/200]: 73.23387414216995\n",
      "[147/200]: 73.91689133644104\n",
      "[148/200]: 73.45117026567459\n",
      "[149/200]: 75.53505516052246\n",
      "[150/200]: 73.8013619184494\n",
      "[151/200]: 72.76574656367302\n",
      "[152/200]: 73.6390263736248\n",
      "[153/200]: 72.17986813187599\n",
      "[154/200]: 72.42354047298431\n",
      "[155/200]: 74.80989915132523\n",
      "[156/200]: 73.2467320561409\n",
      "[157/200]: 71.8396734893322\n",
      "[158/200]: 70.43014317750931\n",
      "[159/200]: 71.32958072423935\n",
      "[160/200]: 70.75854170322418\n",
      "[161/200]: 71.63116580247879\n",
      "[162/200]: 71.36292791366577\n",
      "[163/200]: 73.84477642178535\n",
      "[164/200]: 74.20330628752708\n",
      "[165/200]: 72.64204815030098\n",
      "[166/200]: 72.48518499732018\n",
      "[167/200]: 71.0563400387764\n",
      "[168/200]: 70.78481596708298\n",
      "[169/200]: 71.43198081851006\n",
      "[170/200]: 70.1828980743885\n",
      "[171/200]: 70.92765012383461\n",
      "[172/200]: 70.79980766773224\n",
      "[173/200]: 69.69856950640678\n",
      "[174/200]: 69.24087205529213\n",
      "[175/200]: 69.55652013421059\n",
      "[176/200]: 69.77246594429016\n",
      "[177/200]: 69.56942290067673\n",
      "[178/200]: 68.4418016076088\n",
      "[179/200]: 70.7949883043766\n",
      "[180/200]: 71.68316450715065\n",
      "[181/200]: 69.20218649506569\n",
      "[182/200]: 70.92271053791046\n",
      "[183/200]: 69.10866460204124\n",
      "[184/200]: 67.86071088910103\n",
      "[185/200]: 67.41587114334106\n",
      "[186/200]: 68.82118752598763\n",
      "[187/200]: 68.83816891908646\n",
      "[188/200]: 68.9501525759697\n",
      "[189/200]: 67.2659021615982\n",
      "[190/200]: 67.46805873513222\n",
      "[191/200]: 69.2418766617775\n",
      "[192/200]: 67.84349420666695\n",
      "[193/200]: 68.41821524500847\n",
      "[194/200]: 68.97996443510056\n",
      "[195/200]: 68.29283112287521\n",
      "[196/200]: 66.24537009000778\n",
      "[197/200]: 68.68495419621468\n",
      "[198/200]: 68.12819075584412\n",
      "[199/200]: 68.87047591805458\n"
     ]
    }
   ],
   "source": [
    "from itertools import cycle\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir='./runs')\n",
    "\n",
    "cnt = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for item1, item2 in zip(org_dataloader, cycle(pos_dataloader)):\n",
    "        X_batch, _ = item1\n",
    "        X_new_batch, _ = item2\n",
    "\n",
    "        X_batch = X_batch.to(device)\n",
    "        X_new_batch = X_new_batch.to(device)\n",
    "\n",
    "        optimizer_1d.zero_grad()\n",
    "        optimizer_3d.zero_grad()\n",
    "        optimizer_projector.zero_grad()\n",
    "\n",
    "        embedding_1d = extractor_1d(X_batch)\n",
    "        embedding_3d = extractor_3d(X_new_batch)\n",
    "        projected_1d = projector(embedding_1d)\n",
    "        projected_3d = projector(embedding_3d)\n",
    "\n",
    "        loss = loss_fn(projected_1d, projected_3d)\n",
    "        loss.backward()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "        optimizer_1d.step()\n",
    "        optimizer_3d.step()\n",
    "        optimizer_projector.step()\n",
    "\n",
    "    cnt += 1\n",
    "\n",
    "    print(f'[{epoch}/{epochs}]: {total_loss}')\n",
    "    \n",
    "    writer.add_scalar('Loss/train', total_loss, cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4000, 20])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_tensor = torch.tensor(np.expand_dims(X_val, axis=2).transpose((0, 2, 1)), dtype=torch.float32, device=device)\n",
    "\n",
    "X_val_embedding = extractor_1d(X_val_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_embedding = X_val_embedding.cpu().detach().numpy()\n",
    "X_val_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chan/miniconda3/envs/csi5388/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([2.96512651, 3.01782084, 3.64208198, 3.65459371, 4.23379874]),\n",
       " 'score_time': array([0.00241208, 0.00238132, 0.00236225, 0.00237226, 0.00239182]),\n",
       " 'test_score': array([0.67431162, 0.81376944, 0.59952126, 0.59288618, 0.46378186])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "mlp = MLPClassifier(max_iter=500)\n",
    "\n",
    "cross_validate(mlp, X_val_embedding, y_val, cv=5, scoring='f1_macro')\n",
    "\n",
    "# mlp.fit(X_val_embedding, y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 20)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([8.59820437, 3.76568174, 2.80605435, 2.94945192, 3.74656677]),\n",
       " 'score_time': array([0.03523374, 0.03223753, 0.03021288, 0.03036594, 0.03034711]),\n",
       " 'test_score': array([0.56215391, 0.55339958, 0.48419142, 0.60216681, 0.41635716])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "mlp = MLPClassifier(max_iter=500)\n",
    "\n",
    "cross_validate(mlp, X_val, y_val, cv=5, scoring='f1_macro')\n",
    "\n",
    "# mlp.fit(X_val_embedding, y_val)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csi5388",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
