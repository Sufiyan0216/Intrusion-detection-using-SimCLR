{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "from sklearn.utils import resample\n",
    "from collections import Counter\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import helper\n",
    "import dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from resnet1d.net1d import Net1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2830743, 79)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = [name for name in os.listdir('./data')]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for i in range(len(data_files)):\n",
    "    fname = './data/' + data_files[i]\n",
    "    df = pd.read_csv(fname)\n",
    "    # df.columns = [x.strip().lstrip() for x in df.columns]\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2830743, 79)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove spaces in the front and the end of the column names for better human reading\n",
    "df.columns = [x.lstrip().strip().replace('ï¿½', '-') for x in df.columns]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2827876, 79)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace inf values to nan\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove this when experimenting on the whole dataset\n",
    "df = resample(df, replace=False, n_samples=20000, stratify=df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pca__n_components = 20\n",
    "\n",
    "preprocessor = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy='most_frequent')),\n",
    "    (\"normalize\", MinMaxScaler()),\n",
    "    (\"PCA\", PCA(n_components=pca__n_components))\n",
    "])\n",
    "\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Label'], axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_val = preprocessor.transform(X_val)\n",
    "\n",
    "# doing this since we need all labels in case there's any labels not found in test set\n",
    "label_encoder.fit(y)\n",
    "\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 3, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smote, _ = helper.smote_sampling(X_train, y_train)\n",
    "X_gaussion = helper.add_gaussion(X_smote)\n",
    "X_flip = helper.invert_array(X_train)\n",
    "\n",
    "X_new = np.dstack([X_smote, X_gaussion, X_flip])\n",
    "X_new = X_new.transpose((0, 2, 1))\n",
    "\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 1, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch, channel, feature\n",
    "X_train = np.expand_dims(X_train, axis=2).transpose((0, 2, 1))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_dataset = dataset.NumpyDataset(X_train, y_train)\n",
    "pos_dataset = dataset.NumpyDataset(X_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from pytorch_metric_learning.losses import SelfSupervisedLoss, NTXentLoss\n",
    "from models import Extractor, Projector, ExtractorMLP\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "extractor_1d = Extractor(n_features=pca__n_components, n_channels=1).to(device)\n",
    "extractor_3d = Extractor(n_features=pca__n_components, n_channels=3).to(device)\n",
    "\n",
    "# extractor_1d = ExtractorMLP(n_features=pca__n_components, n_channels=1).to(device)\n",
    "# extractor_3d = Extractor(n_features=pca__n_components, n_channels=3).to(device)\n",
    "\n",
    "\n",
    "projector = Projector().to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-4\n",
    "batch_size = 768\n",
    "epochs = 200\n",
    "\n",
    "org_dataloader = DataLoader(org_dataset, batch_size=batch_size,)\n",
    "pos_dataloader = DataLoader(pos_dataset, batch_size=batch_size)\n",
    "\n",
    "optimizer_1d = torch.optim.Adam(extractor_1d.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "optimizer_3d = torch.optim.Adam(extractor_3d.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "optimizer_projector = torch.optim.Adam(projector.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "loss_fn = NTXentLoss()\n",
    "loss_fn = SelfSupervisedLoss(loss_fn, symmetric=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/200]: 138.25887727737427\n",
      "[1/200]: 129.1943917274475\n",
      "[2/200]: 112.87743520736694\n",
      "[3/200]: 97.78681898117065\n",
      "[4/200]: 87.58734321594238\n",
      "[5/200]: 80.99812507629395\n",
      "[6/200]: 77.1276319026947\n",
      "[7/200]: 73.54132580757141\n",
      "[8/200]: 70.65895175933838\n",
      "[9/200]: 68.08123779296875\n",
      "[10/200]: 65.85488414764404\n",
      "[11/200]: 64.05440402030945\n",
      "[12/200]: 62.77361512184143\n",
      "[13/200]: 61.11018657684326\n",
      "[14/200]: 59.63137483596802\n",
      "[15/200]: 58.29786682128906\n",
      "[16/200]: 57.53602623939514\n",
      "[17/200]: 55.28964924812317\n",
      "[18/200]: 54.52732014656067\n",
      "[19/200]: 52.89133810997009\n",
      "[20/200]: 51.78991341590881\n",
      "[21/200]: 50.854888677597046\n",
      "[22/200]: 49.62147259712219\n",
      "[23/200]: 48.403154253959656\n",
      "[24/200]: 48.74461889266968\n",
      "[25/200]: 48.40158033370972\n",
      "[26/200]: 47.0635529756546\n",
      "[27/200]: 46.64481317996979\n",
      "[28/200]: 49.47373044490814\n",
      "[29/200]: 45.84053027629852\n",
      "[30/200]: 45.90511131286621\n",
      "[31/200]: 44.6131774187088\n",
      "[32/200]: 46.40576481819153\n",
      "[33/200]: 45.28226184844971\n",
      "[34/200]: 44.606194376945496\n",
      "[35/200]: 44.39935564994812\n",
      "[36/200]: 44.21140217781067\n",
      "[37/200]: 43.16757667064667\n",
      "[38/200]: 42.272271275520325\n",
      "[39/200]: 42.991100668907166\n",
      "[40/200]: 42.81129837036133\n",
      "[41/200]: 43.05332636833191\n",
      "[42/200]: 42.56348240375519\n",
      "[43/200]: 40.99716854095459\n",
      "[44/200]: 42.41958427429199\n",
      "[45/200]: 40.53195667266846\n",
      "[46/200]: 42.34305477142334\n",
      "[47/200]: 40.98062217235565\n",
      "[48/200]: 39.239967346191406\n",
      "[49/200]: 39.24471735954285\n",
      "[50/200]: 42.422056913375854\n",
      "[51/200]: 39.959760665893555\n",
      "[52/200]: 40.45489168167114\n",
      "[53/200]: 40.5528302192688\n",
      "[54/200]: 38.45758903026581\n",
      "[55/200]: 39.0604213476181\n",
      "[56/200]: 39.39752745628357\n",
      "[57/200]: 38.221558928489685\n",
      "[58/200]: 38.16015887260437\n",
      "[59/200]: 38.770880699157715\n",
      "[60/200]: 38.80389189720154\n",
      "[61/200]: 38.592302560806274\n",
      "[62/200]: 38.11142814159393\n",
      "[63/200]: 37.352275133132935\n",
      "[64/200]: 37.110116958618164\n",
      "[65/200]: 36.15411961078644\n",
      "[66/200]: 36.48149037361145\n",
      "[67/200]: 36.36552536487579\n",
      "[68/200]: 36.50205183029175\n",
      "[69/200]: 37.02379822731018\n",
      "[70/200]: 36.492517828941345\n",
      "[71/200]: 36.049628496170044\n",
      "[72/200]: 35.761688351631165\n",
      "[73/200]: 37.957396268844604\n",
      "[74/200]: 36.81335961818695\n",
      "[75/200]: 35.355058908462524\n",
      "[76/200]: 36.01333260536194\n",
      "[77/200]: 33.87313449382782\n",
      "[78/200]: 35.28577971458435\n",
      "[79/200]: 35.67294883728027\n",
      "[80/200]: 35.62377655506134\n",
      "[81/200]: 35.56191635131836\n",
      "[82/200]: 33.05313324928284\n",
      "[83/200]: 33.71057832241058\n",
      "[84/200]: 33.866830348968506\n",
      "[85/200]: 33.22955667972565\n",
      "[86/200]: 32.5483832359314\n",
      "[87/200]: 33.016491174697876\n",
      "[88/200]: 35.08087646961212\n",
      "[89/200]: 35.39435398578644\n",
      "[90/200]: 33.91257345676422\n",
      "[91/200]: 34.60464382171631\n",
      "[92/200]: 34.6646409034729\n",
      "[93/200]: 34.798155188560486\n",
      "[94/200]: 34.290345788002014\n",
      "[95/200]: 33.11662948131561\n",
      "[96/200]: 33.91329872608185\n",
      "[97/200]: 32.95264983177185\n",
      "[98/200]: 31.936428546905518\n",
      "[99/200]: 33.48196315765381\n",
      "[100/200]: 33.31233191490173\n",
      "[101/200]: 32.25127673149109\n",
      "[102/200]: 32.16444492340088\n",
      "[103/200]: 33.825483322143555\n",
      "[104/200]: 31.921716809272766\n",
      "[105/200]: 31.811391949653625\n",
      "[106/200]: 30.45344841480255\n",
      "[107/200]: 30.988691210746765\n",
      "[108/200]: 31.876542925834656\n",
      "[109/200]: 30.069376349449158\n",
      "[110/200]: 31.52062714099884\n",
      "[111/200]: 31.32397949695587\n",
      "[112/200]: 30.421936511993408\n",
      "[113/200]: 31.00621724128723\n",
      "[114/200]: 31.673078656196594\n",
      "[115/200]: 31.379797101020813\n",
      "[116/200]: 29.145769596099854\n",
      "[117/200]: 30.163312554359436\n",
      "[118/200]: 30.68196964263916\n",
      "[119/200]: 31.26657807826996\n",
      "[120/200]: 32.1324577331543\n",
      "[121/200]: 31.12714183330536\n",
      "[122/200]: 31.3683203458786\n",
      "[123/200]: 34.031423926353455\n",
      "[124/200]: 32.60408139228821\n",
      "[125/200]: 30.93007266521454\n",
      "[126/200]: 31.43471384048462\n",
      "[127/200]: 31.929393887519836\n",
      "[128/200]: 29.36480462551117\n",
      "[129/200]: 28.997863292694092\n",
      "[130/200]: 29.603841423988342\n",
      "[131/200]: 31.6787987947464\n",
      "[132/200]: 31.06332552433014\n",
      "[133/200]: 29.04484498500824\n",
      "[134/200]: 31.028756380081177\n",
      "[135/200]: 30.074677228927612\n",
      "[136/200]: 32.57497811317444\n",
      "[137/200]: 30.094457983970642\n",
      "[138/200]: 31.60159122943878\n",
      "[139/200]: 29.049736738204956\n",
      "[140/200]: 29.324771523475647\n",
      "[141/200]: 29.80991792678833\n",
      "[142/200]: 32.27264988422394\n",
      "[143/200]: 30.213621854782104\n",
      "[144/200]: 31.576470375061035\n",
      "[145/200]: 29.594350457191467\n",
      "[146/200]: 29.244903564453125\n",
      "[147/200]: 31.441534161567688\n",
      "[148/200]: 29.086170196533203\n",
      "[149/200]: 28.12105441093445\n",
      "[150/200]: 28.394774794578552\n",
      "[151/200]: 28.477081775665283\n",
      "[152/200]: 28.675259947776794\n",
      "[153/200]: 27.748725056648254\n",
      "[154/200]: 27.78367555141449\n",
      "[155/200]: 27.529367208480835\n",
      "[156/200]: 28.206064343452454\n",
      "[157/200]: 29.17901837825775\n",
      "[158/200]: 29.439669728279114\n",
      "[159/200]: 28.319366335868835\n",
      "[160/200]: 29.156025528907776\n",
      "[161/200]: 27.52799701690674\n",
      "[162/200]: 30.91248846054077\n",
      "[163/200]: 30.817366242408752\n",
      "[164/200]: 28.373780727386475\n",
      "[165/200]: 27.21925723552704\n",
      "[166/200]: 27.138068675994873\n",
      "[167/200]: 26.84770369529724\n",
      "[168/200]: 27.592959880828857\n",
      "[169/200]: 28.016245126724243\n",
      "[170/200]: 27.274917006492615\n",
      "[171/200]: 26.65335476398468\n",
      "[172/200]: 26.684465646743774\n",
      "[173/200]: 27.99912941455841\n",
      "[174/200]: 27.309730052947998\n",
      "[175/200]: 28.465643525123596\n",
      "[176/200]: 28.134754419326782\n",
      "[177/200]: 28.449958562850952\n",
      "[178/200]: 27.205896735191345\n",
      "[179/200]: 27.040804028511047\n",
      "[180/200]: 26.082576870918274\n",
      "[181/200]: 28.388505220413208\n",
      "[182/200]: 29.710225582122803\n",
      "[183/200]: 29.19640576839447\n",
      "[184/200]: 27.17363429069519\n",
      "[185/200]: 27.3800265789032\n",
      "[186/200]: 27.62424945831299\n",
      "[187/200]: 27.182225942611694\n",
      "[188/200]: 25.65955424308777\n",
      "[189/200]: 26.41722071170807\n",
      "[190/200]: 30.03368043899536\n",
      "[191/200]: 25.73172676563263\n",
      "[192/200]: 26.23581349849701\n",
      "[193/200]: 26.101207375526428\n",
      "[194/200]: 26.321845293045044\n",
      "[195/200]: 25.104358077049255\n",
      "[196/200]: 25.972493171691895\n",
      "[197/200]: 24.756951451301575\n",
      "[198/200]: 28.09201228618622\n",
      "[199/200]: 29.288928985595703\n"
     ]
    }
   ],
   "source": [
    "from itertools import cycle\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir='./runs')\n",
    "\n",
    "cnt = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for item1, item2 in zip(org_dataloader, cycle(pos_dataloader)):\n",
    "        X_batch, _ = item1\n",
    "        X_new_batch, _ = item2\n",
    "\n",
    "        X_batch = X_batch.to(device)\n",
    "        X_new_batch = X_new_batch.to(device)\n",
    "\n",
    "        optimizer_1d.zero_grad()\n",
    "        optimizer_3d.zero_grad()\n",
    "        optimizer_projector.zero_grad()\n",
    "\n",
    "        embedding_1d = extractor_1d(X_batch)\n",
    "        embedding_3d = extractor_3d(X_new_batch)\n",
    "        projected_1d = projector(embedding_1d)\n",
    "        projected_3d = projector(embedding_3d)\n",
    "\n",
    "        loss = loss_fn(projected_1d, projected_3d)\n",
    "        loss.backward()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "        optimizer_1d.step()\n",
    "        optimizer_3d.step()\n",
    "        optimizer_projector.step()\n",
    "\n",
    "    cnt += 1\n",
    "\n",
    "    print(f'[{epoch}/{epochs}]: {total_loss}')\n",
    "    \n",
    "    writer.add_scalar('Loss/train', total_loss, cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_tensor = torch.tensor(np.expand_dims(X_val, axis=2).transpose((0, 2, 1)), dtype=torch.float32, device=device)\n",
    "\n",
    "X_val_embedding = extractor_1d(X_val_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_embedding = X_val_embedding.cpu().detach().numpy()\n",
    "X_val_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chan/miniconda3/envs/csi5388/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([3.65506697, 3.0108037 , 4.12173891, 4.20474267, 4.94763851]),\n",
       " 'score_time': array([0.00244713, 0.00234199, 0.00295568, 0.00235939, 0.00236249]),\n",
       " 'test_score': array([0.67292007, 0.61829282, 0.81724516, 0.68256309, 0.67819363])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "mlp = MLPClassifier(max_iter=500)\n",
    "\n",
    "cross_validate(mlp, X_val_embedding, y_val, cv=5, scoring='f1_macro')\n",
    "\n",
    "# mlp.fit(X_val_embedding, y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.693842954"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0.67292007, 0.61829282, 0.81724516, 0.68256309, 0.67819363]\n",
    "np.average(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 20)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chan/miniconda3/envs/csi5388/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chan/miniconda3/envs/csi5388/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/chan/miniconda3/envs/csi5388/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/chan/miniconda3/envs/csi5388/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([5.38574505, 4.82814479, 6.06449866, 5.98018837, 6.25218582]),\n",
       " 'score_time': array([0.00291109, 0.00246525, 0.00245214, 0.00243998, 0.00264978]),\n",
       " 'test_score': array([0.71735317, 0.70128685, 0.79946408, 0.61093661, 0.57379517])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "mlp = MLPClassifier(max_iter=500)\n",
    "\n",
    "cross_validate(mlp, X_val, y_val, cv=5, scoring='f1_macro')\n",
    "\n",
    "# mlp.fit(X_val_embedding, y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.680567176"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0.71735317, 0.70128685, 0.79946408, 0.61093661, 0.57379517]\n",
    "np.average(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csi5388",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
