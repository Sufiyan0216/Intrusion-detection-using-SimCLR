{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "from sklearn.utils import resample\n",
    "from collections import Counter\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import helper\n",
    "import dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from resnet1d.net1d import Net1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2830743, 79)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = [name for name in os.listdir('./data')]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for i in range(len(data_files)):\n",
    "    fname = './data/' + data_files[i]\n",
    "    df = pd.read_csv(fname)\n",
    "    # df.columns = [x.strip().lstrip() for x in df.columns]\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2830743, 79)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove spaces in the front and the end of the column names for better human reading\n",
    "df.columns = [x.lstrip().strip().replace('�', '-') for x in df.columns]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2827876, 79)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace inf values to nan\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df, stratify=df['Label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'BENIGN': 1817055,\n",
       "         'DoS Hulk': 184099,\n",
       "         'PortScan': 127043,\n",
       "         'DDoS': 102420,\n",
       "         'DoS GoldenEye': 8234,\n",
       "         'FTP-Patator': 6348,\n",
       "         'SSH-Patator': 4717,\n",
       "         'DoS slowloris': 4637,\n",
       "         'DoS Slowhttptest': 4399,\n",
       "         'Bot': 1565,\n",
       "         'Web Attack � Brute Force': 1206,\n",
       "         'Web Attack � XSS': 522,\n",
       "         'Infiltration': 29,\n",
       "         'Web Attack � Sql Injection': 17,\n",
       "         'Heartbleed': 9})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'BENIGN': 206780,\n",
       "         'DoS Hulk': 92049,\n",
       "         'PortScan': 63521,\n",
       "         'DDoS': 51210,\n",
       "         'DoS GoldenEye': 8234,\n",
       "         'FTP-Patator': 6348,\n",
       "         'SSH-Patator': 4717,\n",
       "         'DoS slowloris': 4637,\n",
       "         'DoS Slowhttptest': 4399,\n",
       "         'Bot': 1565,\n",
       "         'Web Attack � Brute Force': 1206,\n",
       "         'Web Attack � XSS': 522,\n",
       "         'Infiltration': 29,\n",
       "         'Web Attack � Sql Injection': 17,\n",
       "         'Heartbleed': 9})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "sampling_strategy = dict(Counter(df_train['Label']))\n",
    "attack_cnt = 0\n",
    "\n",
    "for k, v in sampling_strategy.items():\n",
    "    if v < 20000 or k == 'BENIGN': continue\n",
    "\n",
    "    # when samples count bigger than 10k, truncate in half\n",
    "    sampling_strategy[k] = v // 2\n",
    "    attack_cnt += v // 2\n",
    "\n",
    "sampling_strategy['BENIGN'] = attack_cnt\n",
    "\n",
    "under_sampler = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
    "\n",
    "X_train = df_train.drop(['Label'], axis=1)\n",
    "y_train = df_train['Label']\n",
    "\n",
    "X_train, y_train = under_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "print(y_train.shape[0])\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pca__n_components = 20\n",
    "\n",
    "preprocessor = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy='most_frequent')),\n",
    "    (\"normalize\", MinMaxScaler()),\n",
    "    (\"PCA\", PCA(n_components=pca__n_components))\n",
    "])\n",
    "\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# doing this since we need all labels in case there's any labels not found in test set\n",
    "label_encoder.fit(df['Label'])\n",
    "\n",
    "y_train = label_encoder.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dist/preprocessor-mlp.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "\n",
    "with open('./dist/labelencoder-mlp.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gen argument views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445243, 3, 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smote, _ = helper.smote_sampling(X_train, y_train)\n",
    "X_gaussion = helper.add_gaussion(X_smote)\n",
    "X_flip = helper.invert_array(X_train)\n",
    "\n",
    "X_new = np.dstack([X_smote, X_gaussion, X_flip])\n",
    "X_new = X_new.transpose((0, 2, 1))\n",
    "\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445243, 1, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.expand_dims(X_train, axis=2).transpose((0, 2, 1))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_dataset = dataset.NumpyDataset(X_train, y_train)\n",
    "pos_dataset = dataset.NumpyDataset(X_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best params found by hyper parameters tunning\n",
    "# best_params = {'embedding_size': 34, 'lr': 0.010848038400629992, 'weight_decay': 0.00012209180832556052}\n",
    "best_params = {'lr': 0.014968162145540436, 'weight_decay': 0.002904245255012199, 'hidden_size': 65, 'n_hidden': 1, 'embedding_size': 39, 'kernel_size': 1, 'stride': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train models & checkpoints are saved as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/200]: 2238.133773326874\n",
      "[2/200]: 2175.31924366951\n",
      "[3/200]: 2004.3610863685608\n",
      "[4/200]: 1988.527984380722\n",
      "[5/200]: 2006.5619750022888\n",
      "[6/200]: 1959.9978439807892\n",
      "[7/200]: 1926.7197148799896\n",
      "[8/200]: 2010.106299161911\n",
      "[9/200]: 2067.2433507442474\n",
      "[10/200]: 1906.306254863739\n",
      "[11/200]: 1878.50435256958\n",
      "[12/200]: 1864.6345417499542\n",
      "[13/200]: 1838.0951924324036\n",
      "[14/200]: 1780.104879617691\n",
      "[15/200]: 1792.5136587619781\n",
      "[16/200]: 1753.2039589881897\n",
      "[17/200]: 1756.9024851322174\n",
      "[18/200]: 1821.3619267940521\n",
      "[19/200]: 1734.990210056305\n",
      "[20/200]: 1823.2698986530304\n",
      "[21/200]: 1728.6076302528381\n",
      "[22/200]: 1730.9255759716034\n",
      "[23/200]: 1703.6616468429565\n",
      "[24/200]: 1689.3443677425385\n",
      "[25/200]: 1641.8360650539398\n",
      "[26/200]: 1711.3743152618408\n",
      "[27/200]: 1672.6423416137695\n",
      "[28/200]: 1637.66059923172\n",
      "[29/200]: 1688.1354579925537\n",
      "[30/200]: 1716.2706863880157\n",
      "[31/200]: 1665.3287148475647\n",
      "[32/200]: 1633.8278710842133\n",
      "[33/200]: 1643.926919221878\n",
      "[34/200]: 1672.1975548267365\n",
      "[35/200]: 1634.0799219608307\n",
      "[36/200]: 1613.8323698043823\n",
      "[37/200]: 1601.0042560100555\n",
      "[38/200]: 1601.4780349731445\n",
      "[39/200]: 1648.0146827697754\n",
      "[40/200]: 1584.090011358261\n",
      "[41/200]: 1826.3042590618134\n",
      "[42/200]: 1820.2404415607452\n",
      "[43/200]: 1709.1880388259888\n",
      "[44/200]: 1632.7554459571838\n",
      "[45/200]: 1643.9233512878418\n",
      "[46/200]: 1646.5203318595886\n",
      "[47/200]: 1611.970895767212\n",
      "[48/200]: 1637.5531668663025\n",
      "[49/200]: 1573.5616326332092\n",
      "[50/200]: 1514.243246793747\n",
      "[51/200]: 1568.9425480365753\n",
      "[52/200]: 1534.3740620613098\n",
      "[53/200]: 1571.2098195552826\n",
      "[54/200]: 1601.2748403549194\n",
      "[55/200]: 1691.0861160755157\n",
      "[56/200]: 1849.4100844860077\n",
      "[57/200]: 1641.1599423885345\n",
      "[58/200]: 1688.665374994278\n",
      "[59/200]: 1590.7105269432068\n",
      "[60/200]: 1543.7574808597565\n",
      "[61/200]: 1566.2581565380096\n",
      "[62/200]: 1561.829509973526\n",
      "[63/200]: 1577.362985610962\n",
      "[64/200]: 1506.6918125152588\n",
      "[65/200]: 1520.8835456371307\n",
      "[66/200]: 1492.5272965431213\n",
      "[67/200]: 1612.2494206428528\n",
      "[68/200]: 1601.5568871498108\n",
      "[69/200]: 1646.4387075901031\n",
      "[70/200]: 1504.286996126175\n",
      "[71/200]: 1469.4867436885834\n",
      "[72/200]: 1475.4453961849213\n",
      "[73/200]: 1560.8760080337524\n",
      "[74/200]: 1482.9305837154388\n",
      "[75/200]: 1536.0062501430511\n",
      "[76/200]: 1487.308965921402\n",
      "[77/200]: 1480.7594051361084\n",
      "[78/200]: 1679.1302654743195\n",
      "[79/200]: 1651.674451828003\n",
      "[80/200]: 1567.102510690689\n",
      "[81/200]: 1462.3994929790497\n",
      "[82/200]: 1463.3543181419373\n",
      "[83/200]: 1475.4131042957306\n",
      "[84/200]: 1453.3432688713074\n",
      "[85/200]: 1497.6366181373596\n",
      "[86/200]: 1414.8494803905487\n",
      "[87/200]: 1467.3162684440613\n",
      "[88/200]: 1746.274061203003\n",
      "[89/200]: 1593.3516201972961\n",
      "[90/200]: 1497.9281249046326\n",
      "[91/200]: 1525.5942492485046\n",
      "[92/200]: 1477.6626236438751\n",
      "[93/200]: 1437.7561404705048\n",
      "[94/200]: 1428.3581867218018\n",
      "[95/200]: 1384.8589181900024\n",
      "[96/200]: 1449.8380521535873\n",
      "[97/200]: 1790.8989725112915\n",
      "[98/200]: 1577.0261509418488\n",
      "[99/200]: 1495.9420969486237\n",
      "[100/200]: 1486.411311864853\n",
      "[101/200]: 1503.603482246399\n",
      "[102/200]: 1433.3955240249634\n",
      "[103/200]: 1417.8793308734894\n",
      "[104/200]: 1392.9837229251862\n",
      "[105/200]: 1548.8338289260864\n",
      "[106/200]: 1392.0020871162415\n",
      "[107/200]: 1412.4515273571014\n",
      "[108/200]: 1368.801174879074\n",
      "[109/200]: 1458.304337978363\n",
      "[110/200]: 1464.0973801612854\n",
      "[111/200]: 1367.3797928094864\n",
      "[112/200]: 1316.639556646347\n",
      "[113/200]: 1437.062031507492\n",
      "[114/200]: 1361.6344945430756\n",
      "[115/200]: 1323.845575094223\n",
      "[116/200]: 1316.5266567468643\n",
      "[117/200]: 1520.0420804023743\n",
      "[118/200]: 1380.7870259284973\n",
      "[119/200]: 1607.213176727295\n",
      "[120/200]: 1539.248883485794\n",
      "[121/200]: 1443.425937652588\n",
      "[122/200]: 1364.4730553627014\n",
      "[123/200]: 1440.236566066742\n",
      "[124/200]: 1416.2925761938095\n",
      "[125/200]: 1429.2519619464874\n",
      "[126/200]: 1443.7241220474243\n",
      "[127/200]: 1706.8693594932556\n",
      "[128/200]: 1717.4309077262878\n",
      "[129/200]: 1550.8341760635376\n",
      "[130/200]: 1524.0991840362549\n",
      "[131/200]: 1647.1870121955872\n",
      "[132/200]: 1496.1160900592804\n",
      "[133/200]: 1381.3746025562286\n",
      "[134/200]: 1569.9380240440369\n",
      "[135/200]: 1401.499277830124\n",
      "[136/200]: 1540.2035503387451\n",
      "[137/200]: 1824.8790438175201\n",
      "[138/200]: 1654.19944024086\n",
      "[139/200]: 1572.0299806594849\n",
      "[140/200]: 1516.6433925628662\n",
      "[141/200]: 1441.6631042957306\n",
      "[142/200]: 1666.5040347576141\n",
      "[143/200]: 1449.0344457626343\n",
      "[144/200]: 1525.8231971263885\n",
      "[145/200]: 1375.2203323841095\n",
      "[146/200]: 1633.514238834381\n",
      "[147/200]: 1509.675597667694\n",
      "[148/200]: 1548.887146472931\n",
      "[149/200]: 1495.4573385715485\n",
      "[150/200]: 1452.1857407093048\n",
      "[151/200]: 1363.740700006485\n",
      "[152/200]: 1464.4664146900177\n",
      "[153/200]: 1446.8979930877686\n",
      "[154/200]: 1452.0535418987274\n",
      "[155/200]: 1389.6349940299988\n",
      "[156/200]: 1441.0672657489777\n",
      "[157/200]: 1362.960459947586\n",
      "[158/200]: 1527.944427728653\n",
      "[159/200]: 1377.4376657009125\n",
      "[160/200]: 1404.092936038971\n",
      "[161/200]: 1400.2724981307983\n",
      "[162/200]: 1607.5695111751556\n",
      "[163/200]: 1590.2483808994293\n",
      "[164/200]: 1468.0241045951843\n",
      "[165/200]: 1725.3166801929474\n",
      "[166/200]: 1547.7323698997498\n",
      "[167/200]: 1408.5257411003113\n",
      "[168/200]: 1358.8897964954376\n",
      "[169/200]: 1398.7183601856232\n",
      "[170/200]: 1467.598620414734\n",
      "[171/200]: 1416.9667863845825\n",
      "[172/200]: 1268.4820868968964\n",
      "[173/200]: 1280.0650210380554\n",
      "[174/200]: 1549.8517508506775\n",
      "[175/200]: 1731.7886295318604\n",
      "[176/200]: 1782.9605712890625\n",
      "[177/200]: 1644.5155684947968\n",
      "[178/200]: 1547.5134899616241\n",
      "[179/200]: 1448.1046991348267\n",
      "[180/200]: 1480.024516582489\n",
      "[181/200]: 1355.933482170105\n",
      "[182/200]: 1562.1052205562592\n",
      "[183/200]: 1497.6523280143738\n",
      "[184/200]: 1640.729332447052\n",
      "[185/200]: 1686.545538187027\n",
      "[186/200]: 1548.4305877685547\n",
      "[187/200]: 1412.7946026325226\n",
      "[188/200]: 1412.430169582367\n",
      "[189/200]: 1584.8098449707031\n",
      "[190/200]: 1435.4568374156952\n",
      "[191/200]: 1440.5238673686981\n",
      "[192/200]: 1421.7257719039917\n",
      "[193/200]: 1352.054489850998\n",
      "[194/200]: 1350.2480149269104\n",
      "[195/200]: 1360.406803369522\n",
      "[196/200]: 1335.1060338020325\n",
      "[197/200]: 1293.1873531341553\n",
      "[198/200]: 1376.9649661779404\n",
      "[199/200]: 1506.3008666038513\n",
      "[200/200]: 1359.4998924732208\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "import optuna\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_metric_learning.losses import SelfSupervisedLoss, NTXentLoss\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from models import Extractor, Projector, ExtractorMLP\n",
    "from models import ExtractorMLP\n",
    "from itertools import cycle\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "embedding_size = best_params['embedding_size']\n",
    "kernel_size = best_params['kernel_size']\n",
    "stride = best_params['stride']\n",
    "n_hidden = best_params['n_hidden']\n",
    "hidden_size = best_params['hidden_size']\n",
    "act = 'relu'\n",
    "\n",
    "\n",
    "# extractor_1d = Extractor(n_features=pca__n_components, n_channels=1, embedding_size=embedding_size).to(device)\n",
    "# extractor_3d = Extractor(n_features=pca__n_components, n_channels=3, embedding_size=embedding_size).to(device)\n",
    "\n",
    "extractor_1d = ExtractorMLP(n_features=pca__n_components, \n",
    "                        n_channels=1,\n",
    "                        embedding_size=embedding_size,\n",
    "                        hidden_size=hidden_size,\n",
    "                        n_hidden=n_hidden,\n",
    "                        kernel_size=kernel_size, \n",
    "                        stride=stride,\n",
    "                        act=act\n",
    "                        ).to(device)\n",
    "\n",
    "extractor_3d = ExtractorMLP(n_features=pca__n_components, \n",
    "                        n_channels=X_new.shape[1],\n",
    "                        embedding_size=embedding_size,\n",
    "                        hidden_size=hidden_size,\n",
    "                        n_hidden=n_hidden,\n",
    "                        kernel_size=kernel_size, \n",
    "                        stride=stride,\n",
    "                        act=act,\n",
    "                        ).to(device)\n",
    "\n",
    "\n",
    "projector = Projector(embedding_size=embedding_size).to(device)\n",
    "\n",
    "lr = best_params['lr']\n",
    "weight_decay = best_params['weight_decay']\n",
    "batch_size = 1024\n",
    "epochs = 200\n",
    "\n",
    "org_dataloader = DataLoader(org_dataset, batch_size=batch_size,)\n",
    "pos_dataloader = DataLoader(pos_dataset, batch_size=batch_size)\n",
    "\n",
    "optimizer_1d = torch.optim.Adam(extractor_1d.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "optimizer_3d = torch.optim.Adam(extractor_3d.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "optimizer_projector = torch.optim.Adam(projector.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "loss_fn = NTXentLoss()\n",
    "loss_fn = SelfSupervisedLoss(loss_fn, symmetric=False).to(device)\n",
    "\n",
    "writer = SummaryWriter(log_dir='./runs')\n",
    "\n",
    "cnt = 0\n",
    "num_epoch2save = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch != 0 and epoch % num_epoch2save == 0:\n",
    "        helper.store_checkpoint(model=extractor_1d, name='extractor1d', epoch=epoch, prefix='mlp')\n",
    "        helper.store_checkpoint(model=extractor_3d, name='extractor3d', epoch=epoch, prefix='mlp')\n",
    "        helper.store_checkpoint(model=projector, name='projector', epoch=epoch, prefix='mlp')\n",
    "\n",
    "    total_loss = 0\n",
    "    for item1, item2 in zip(org_dataloader, cycle(pos_dataloader)):\n",
    "        X_batch, _ = item1\n",
    "        X_new_batch, _ = item2\n",
    "\n",
    "        X_batch = X_batch.to(device)\n",
    "        X_new_batch = X_new_batch.to(device)\n",
    "\n",
    "        optimizer_1d.zero_grad()\n",
    "        optimizer_3d.zero_grad()\n",
    "        optimizer_projector.zero_grad()\n",
    "\n",
    "        embedding_1d = extractor_1d(X_batch)\n",
    "        embedding_3d = extractor_3d(X_new_batch)\n",
    "        projected_1d = projector(embedding_1d)\n",
    "        projected_3d = projector(embedding_3d)\n",
    "\n",
    "        loss = loss_fn(projected_1d, projected_3d)\n",
    "        loss.backward()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "        optimizer_1d.step()\n",
    "        optimizer_3d.step()\n",
    "        optimizer_projector.step()\n",
    "\n",
    "    cnt += 1\n",
    "\n",
    "    print(f'[{epoch+1}/{epochs}]: {total_loss}')\n",
    "    \n",
    "    writer.add_scalar('Loss/train-MLP-prod', total_loss, cnt)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dist/mlp/extractor1d-final.pkl', 'wb') as f:\n",
    "    pickle.dump(extractor_1d, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csi5388",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
