{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "from sklearn.utils import resample\n",
    "from collections import Counter\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import helper\n",
    "import dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from resnet1d.net1d import Net1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2830743, 79)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = [name for name in os.listdir('./data')]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for i in range(len(data_files)):\n",
    "    fname = './data/' + data_files[i]\n",
    "    df = pd.read_csv(fname)\n",
    "    # df.columns = [x.strip().lstrip() for x in df.columns]\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2830743, 79)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove spaces in the front and the end of the column names for better human reading\n",
    "df.columns = [x.lstrip().strip().replace('�', '-') for x in df.columns]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2827876, 79)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace inf values to nan\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df, stratify=df['Label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'BENIGN': 1817055,\n",
       "         'DoS Hulk': 184099,\n",
       "         'PortScan': 127043,\n",
       "         'DDoS': 102420,\n",
       "         'DoS GoldenEye': 8234,\n",
       "         'FTP-Patator': 6348,\n",
       "         'SSH-Patator': 4717,\n",
       "         'DoS slowloris': 4637,\n",
       "         'DoS Slowhttptest': 4399,\n",
       "         'Bot': 1565,\n",
       "         'Web Attack � Brute Force': 1206,\n",
       "         'Web Attack � XSS': 522,\n",
       "         'Infiltration': 29,\n",
       "         'Web Attack � Sql Injection': 17,\n",
       "         'Heartbleed': 9})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'BENIGN': 206780,\n",
       "         'DoS Hulk': 92049,\n",
       "         'PortScan': 63521,\n",
       "         'DDoS': 51210,\n",
       "         'DoS GoldenEye': 8234,\n",
       "         'FTP-Patator': 6348,\n",
       "         'SSH-Patator': 4717,\n",
       "         'DoS slowloris': 4637,\n",
       "         'DoS Slowhttptest': 4399,\n",
       "         'Bot': 1565,\n",
       "         'Web Attack � Brute Force': 1206,\n",
       "         'Web Attack � XSS': 522,\n",
       "         'Infiltration': 29,\n",
       "         'Web Attack � Sql Injection': 17,\n",
       "         'Heartbleed': 9})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "sampling_strategy = dict(Counter(df_train['Label']))\n",
    "attack_cnt = 0\n",
    "\n",
    "for k, v in sampling_strategy.items():\n",
    "    if v < 20000 or k == 'BENIGN': continue\n",
    "\n",
    "    # when samples count bigger than 10k, truncate in half\n",
    "    sampling_strategy[k] = v // 2\n",
    "    attack_cnt += v // 2\n",
    "\n",
    "sampling_strategy['BENIGN'] = attack_cnt\n",
    "\n",
    "under_sampler = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
    "\n",
    "X_train = df_train.drop(['Label'], axis=1)\n",
    "y_train = df_train['Label']\n",
    "\n",
    "X_train, y_train = under_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "print(y_train.shape[0])\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pca__n_components = 20\n",
    "\n",
    "preprocessor = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy='most_frequent')),\n",
    "    (\"normalize\", MinMaxScaler()),\n",
    "    (\"PCA\", PCA(n_components=pca__n_components))\n",
    "])\n",
    "\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# doing this since we need all labels in case there's any labels not found in test set\n",
    "label_encoder.fit(df['Label'])\n",
    "\n",
    "y_train = label_encoder.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dist/preprocessor-resnet.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "\n",
    "with open('./dist/labelencoder-resnet.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445243, 3, 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smote, _ = helper.smote_sampling(X_train, y_train)\n",
    "X_gaussion = helper.add_gaussion(X_smote)\n",
    "X_flip = helper.invert_array(X_train)\n",
    "\n",
    "X_new = np.dstack([X_smote, X_gaussion, X_flip])\n",
    "X_new = X_new.transpose((0, 2, 1))\n",
    "\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445243, 1, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.expand_dims(X_train, axis=2).transpose((0, 2, 1))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_dataset = dataset.NumpyDataset(X_train, y_train)\n",
    "pos_dataset = dataset.NumpyDataset(X_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best params found by hyper parameters tunning\n",
    "best_params = {'embedding_size': 34, 'lr': 0.010848038400629992, 'weight_decay': 0.00012209180832556052}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/200]: 2413.051329135895\n",
      "[2/200]: 2190.4341123104095\n",
      "[3/200]: 2037.429221868515\n",
      "[4/200]: 1893.5873763561249\n",
      "[5/200]: 1847.801521062851\n",
      "[6/200]: 1789.5462653636932\n",
      "[7/200]: 1737.7479269504547\n",
      "[8/200]: 1713.5767991542816\n",
      "[9/200]: 1645.9643623828888\n",
      "[10/200]: 1611.3001580238342\n",
      "[11/200]: 1600.012222290039\n",
      "[12/200]: 1573.8818888664246\n",
      "[13/200]: 1535.1768295764923\n",
      "[14/200]: 1511.9584772586823\n",
      "[15/200]: 1502.646087884903\n",
      "[16/200]: 1491.2352771759033\n",
      "[17/200]: 1575.1760308742523\n",
      "[18/200]: 1444.5855979919434\n",
      "[19/200]: 1458.4291853904724\n",
      "[20/200]: 1405.556879043579\n",
      "[21/200]: 1393.0760142803192\n",
      "[22/200]: 1383.3884732723236\n",
      "[23/200]: 1372.887379169464\n",
      "[24/200]: 1344.930363893509\n",
      "[25/200]: 1345.8906095027924\n",
      "[26/200]: 1402.7776849269867\n",
      "[27/200]: 1334.2850422859192\n",
      "[28/200]: 1358.575767993927\n",
      "[29/200]: 1416.8756594657898\n",
      "[30/200]: 1359.919137954712\n",
      "[31/200]: 1335.1441538333893\n",
      "[32/200]: 1329.8170101642609\n",
      "[33/200]: 1343.576076745987\n",
      "[34/200]: 1284.7523410320282\n",
      "[35/200]: 1293.5357122421265\n",
      "[36/200]: 1279.4192416667938\n",
      "[37/200]: 1348.0964183807373\n",
      "[38/200]: 1444.1313154697418\n",
      "[39/200]: 1287.6171293258667\n",
      "[40/200]: 1361.7743546962738\n",
      "[41/200]: 1329.0214190483093\n",
      "[42/200]: 1287.9698617458344\n",
      "[43/200]: 1289.1866419315338\n",
      "[44/200]: 1252.5371534824371\n",
      "[45/200]: 1248.6921359300613\n",
      "[46/200]: 1249.4429187774658\n",
      "[47/200]: 1313.097077846527\n",
      "[48/200]: 1271.7567855119705\n",
      "[49/200]: 1309.7844400405884\n",
      "[50/200]: 1263.7852091789246\n",
      "[51/200]: 1232.4080733060837\n",
      "[52/200]: 1227.640500664711\n",
      "[53/200]: 1210.566737294197\n",
      "[54/200]: 1213.2257323265076\n",
      "[55/200]: 1427.8427670001984\n",
      "[56/200]: 1255.7285602092743\n",
      "[57/200]: 1211.2024960517883\n",
      "[58/200]: 1202.2061041593552\n",
      "[59/200]: 1186.6276897192001\n",
      "[60/200]: 1245.4128741025925\n",
      "[61/200]: 1246.4707297086716\n",
      "[62/200]: 1250.7506544589996\n",
      "[63/200]: 1233.1638715267181\n",
      "[64/200]: 1212.7210938930511\n",
      "[65/200]: 1202.3414989709854\n",
      "[66/200]: 1214.435268998146\n",
      "[67/200]: 1192.4460481405258\n",
      "[68/200]: 1175.3621462583542\n",
      "[69/200]: 1191.7447749376297\n",
      "[70/200]: 1143.3615182638168\n",
      "[71/200]: 1160.7661386728287\n",
      "[72/200]: 1169.9452008008957\n",
      "[73/200]: 1155.9357125759125\n",
      "[74/200]: 1210.8391643762589\n",
      "[75/200]: 1179.5468286275864\n",
      "[76/200]: 1185.0207810401917\n",
      "[77/200]: 1156.8452401161194\n",
      "[78/200]: 1138.9494651556015\n",
      "[79/200]: 1137.4682331085205\n",
      "[80/200]: 1276.5258096456528\n",
      "[81/200]: 1149.9420012235641\n",
      "[82/200]: 1141.8781464099884\n",
      "[83/200]: 1255.1125040054321\n",
      "[84/200]: 1144.5821866989136\n",
      "[85/200]: 1182.3668065071106\n",
      "[86/200]: 1264.1909568309784\n",
      "[87/200]: 1132.2825741767883\n",
      "[88/200]: 1141.7795635461807\n",
      "[89/200]: 1107.8575055599213\n",
      "[90/200]: 1126.9352233409882\n",
      "[91/200]: 1288.1320374011993\n",
      "[92/200]: 1139.6004321575165\n",
      "[93/200]: 1120.7078657150269\n",
      "[94/200]: 1233.5446705818176\n",
      "[95/200]: 1167.7973964214325\n",
      "[96/200]: 1194.3740112781525\n",
      "[97/200]: 1193.6861752271652\n",
      "[98/200]: 1140.0576804876328\n",
      "[99/200]: 1114.0123155117035\n",
      "[100/200]: 1127.3233224153519\n",
      "[101/200]: 1108.7935975790024\n",
      "[102/200]: 1093.3207514286041\n",
      "[103/200]: 1120.32288813591\n",
      "[104/200]: 1095.8518605232239\n",
      "[105/200]: 1073.3767800331116\n",
      "[106/200]: 1082.2866823673248\n",
      "[107/200]: 1118.7474648952484\n",
      "[108/200]: 1290.3743121623993\n",
      "[109/200]: 1135.389424920082\n",
      "[110/200]: 1095.4894036054611\n",
      "[111/200]: 1175.552453994751\n",
      "[112/200]: 1135.821006178856\n",
      "[113/200]: 1088.6620490550995\n",
      "[114/200]: 1124.1055161952972\n",
      "[115/200]: 1184.5559375286102\n",
      "[116/200]: 1115.475935459137\n",
      "[117/200]: 1108.0961931943893\n",
      "[118/200]: 1083.3543856143951\n",
      "[119/200]: 1111.3412020206451\n",
      "[120/200]: 1083.2806037664413\n",
      "[121/200]: 1097.1422241926193\n",
      "[122/200]: 1090.670932173729\n",
      "[123/200]: 1137.544062614441\n",
      "[124/200]: 1058.1515935659409\n",
      "[125/200]: 1083.1022372245789\n",
      "[126/200]: 1067.8054769039154\n",
      "[127/200]: 1112.7433807849884\n",
      "[128/200]: 1272.2796308994293\n",
      "[129/200]: 1078.3649547100067\n",
      "[130/200]: 1054.4810038805008\n",
      "[131/200]: 1048.290554523468\n",
      "[132/200]: 1061.599962234497\n",
      "[133/200]: 1089.2520550489426\n",
      "[134/200]: 1054.7765152454376\n",
      "[135/200]: 1075.7315783500671\n",
      "[136/200]: 1054.510330080986\n",
      "[137/200]: 1055.1864808797836\n",
      "[138/200]: 1134.1614513397217\n",
      "[139/200]: 1318.6379083395004\n",
      "[140/200]: 1094.4430058002472\n",
      "[141/200]: 1206.7099676132202\n",
      "[142/200]: 1070.9454947710037\n",
      "[143/200]: 1063.9516217708588\n",
      "[144/200]: 1051.3708782196045\n",
      "[145/200]: 1091.5115613937378\n",
      "[146/200]: 1078.8047975301743\n",
      "[147/200]: 1049.9849689006805\n",
      "[148/200]: 1077.112946987152\n",
      "[149/200]: 1077.4196951389313\n",
      "[150/200]: 1058.6227251291275\n",
      "[151/200]: 1071.373603463173\n",
      "[152/200]: 1042.5092760324478\n",
      "[153/200]: 1030.7670283317566\n",
      "[154/200]: 1053.135662317276\n",
      "[155/200]: 1036.8827794790268\n",
      "[156/200]: 1419.7204945087433\n",
      "[157/200]: 1054.687659740448\n",
      "[158/200]: 1164.0859080553055\n",
      "[159/200]: 1040.1404495239258\n",
      "[160/200]: 1037.1109446287155\n",
      "[161/200]: 1073.4337903261185\n",
      "[162/200]: 1041.5464248657227\n",
      "[163/200]: 1273.4591777324677\n",
      "[164/200]: 1060.550918340683\n",
      "[165/200]: 1034.3525383472443\n",
      "[166/200]: 1100.3871562480927\n",
      "[167/200]: 1025.3415098190308\n",
      "[168/200]: 1022.3570275306702\n",
      "[169/200]: 1046.5025206804276\n",
      "[170/200]: 1034.1386855840683\n",
      "[171/200]: 1058.2902647256851\n",
      "[172/200]: 1059.2181293964386\n",
      "[173/200]: 1163.2420040369034\n",
      "[174/200]: 1047.0453827381134\n",
      "[175/200]: 1040.4228922128677\n",
      "[176/200]: 1036.9113943576813\n",
      "[177/200]: 1066.6203385591507\n",
      "[178/200]: 1048.5426774024963\n",
      "[179/200]: 1037.4029502868652\n",
      "[180/200]: 1121.8986171483994\n",
      "[181/200]: 1086.4356904029846\n",
      "[182/200]: 1184.6503601074219\n",
      "[183/200]: 1327.0278944969177\n",
      "[184/200]: 1077.016695022583\n",
      "[185/200]: 1062.3925737142563\n",
      "[186/200]: 1083.6131174564362\n",
      "[187/200]: 1038.9698276519775\n",
      "[188/200]: 1048.091994524002\n",
      "[189/200]: 1097.3515555858612\n",
      "[190/200]: 1090.7790541648865\n",
      "[191/200]: 1044.5871646404266\n",
      "[192/200]: 1073.361494421959\n",
      "[193/200]: 1049.4267935752869\n",
      "[194/200]: 1048.8144631385803\n",
      "[195/200]: 1042.8949072360992\n",
      "[196/200]: 1185.5319039821625\n",
      "[197/200]: 1036.9818716049194\n",
      "[198/200]: 1034.5393970012665\n",
      "[199/200]: 1025.2426427602768\n",
      "[200/200]: 1112.3130501508713\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "import optuna\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_metric_learning.losses import SelfSupervisedLoss, NTXentLoss\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from models import Extractor, Projector, ExtractorMLP\n",
    "from models import ExtractorMLP\n",
    "from itertools import cycle\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "embedding_size = best_params['embedding_size']\n",
    "\n",
    "extractor_1d = Extractor(n_features=pca__n_components, n_channels=1, embedding_size=embedding_size).to(device)\n",
    "extractor_3d = Extractor(n_features=pca__n_components, n_channels=3, embedding_size=embedding_size).to(device)\n",
    "\n",
    "projector = Projector(embedding_size=embedding_size).to(device)\n",
    "\n",
    "lr = best_params['lr']\n",
    "weight_decay = best_params['weight_decay']\n",
    "batch_size = 1024\n",
    "epochs = 200\n",
    "\n",
    "org_dataloader = DataLoader(org_dataset, batch_size=batch_size,)\n",
    "pos_dataloader = DataLoader(pos_dataset, batch_size=batch_size)\n",
    "\n",
    "optimizer_1d = torch.optim.Adam(extractor_1d.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "optimizer_3d = torch.optim.Adam(extractor_3d.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "optimizer_projector = torch.optim.Adam(projector.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "loss_fn = NTXentLoss()\n",
    "loss_fn = SelfSupervisedLoss(loss_fn, symmetric=False).to(device)\n",
    "\n",
    "writer = SummaryWriter(log_dir='./runs')\n",
    "\n",
    "cnt = 0\n",
    "num_epoch2save = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch != 0 and epoch % num_epoch2save == 0:\n",
    "        helper.store_checkpoint(model=extractor_1d, name='extractor1d', epoch=epoch, prefix='resnet')\n",
    "        helper.store_checkpoint(model=extractor_3d, name='extractor3d', epoch=epoch, prefix='resnet')\n",
    "        helper.store_checkpoint(model=projector, name='projector', epoch=epoch, prefix='resnet')\n",
    "\n",
    "    total_loss = 0\n",
    "    for item1, item2 in zip(org_dataloader, cycle(pos_dataloader)):\n",
    "        X_batch, _ = item1\n",
    "        X_new_batch, _ = item2\n",
    "\n",
    "        X_batch = X_batch.to(device)\n",
    "        X_new_batch = X_new_batch.to(device)\n",
    "\n",
    "        optimizer_1d.zero_grad()\n",
    "        optimizer_3d.zero_grad()\n",
    "        optimizer_projector.zero_grad()\n",
    "\n",
    "        embedding_1d = extractor_1d(X_batch)\n",
    "        embedding_3d = extractor_3d(X_new_batch)\n",
    "        projected_1d = projector(embedding_1d)\n",
    "        projected_3d = projector(embedding_3d)\n",
    "\n",
    "        loss = loss_fn(projected_1d, projected_3d)\n",
    "        loss.backward()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "        optimizer_1d.step()\n",
    "        optimizer_3d.step()\n",
    "        optimizer_projector.step()\n",
    "\n",
    "    cnt += 1\n",
    "\n",
    "    print(f'[{epoch+1}/{epochs}]: {total_loss}')\n",
    "    \n",
    "    writer.add_scalar('Loss/train-Resnet50-prod', total_loss, cnt)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dist/resnet/extractor1d-final.pkl', 'wb') as f:\n",
    "    pickle.dump(extractor_1d, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csi5388",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
